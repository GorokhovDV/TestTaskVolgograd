# Тестовое задание
## Схематичное представление архитектуры
![Image alt](https://github.com/GorokhovDV/TestTaskVolgograd/raw/master/images/scheme.gif)
## Решение задачи
Для решения поставленной задачи предлагается реализовать программный комплекс, который включал бы следующие подсистемы:
0. Инфраструктура на физическом уровне
1. Система организации очередей
2. Система обработки поступивших сообщений
3. Система долговременного хранения не реляционных данных
4. Система долговременного хранения реляционных данных
5. Система обработки сообщений из долговременного хранилища и отдача сообщений клиенту (API)
6. Описание принципов решения задачи
7. Программный код части поставленной задачи 
### 0. Инфраструктура на физическом уровне
Для реализации поставленной задачи в масштабах, необходимых для обеспечения безотказного функционирования системы (в условиях задачи отсутствуют требования по отказоустойчивости и не определена нагрузка на приложение), предлагается использовать: 
* либо кластер из минимум 3-х физических серверов объединенных в общее дисковое пространство с помощью технологии Ceph и настроенных на этих серверах отдельных виртуальных машинах для подсистем: 1. хранения не реляционных данных, 2. хранения реляционных данных, 3. подсистемы организации очередей, 4. остальное пространство (в рамках 30-40% оставшихся мощностей) организовать как систему оркестровки Kubernetes на которой разместить все необходимые сервисы. Оставшиеся мощности кластера оставить под развитие системы.
* либо использовать уже готовые облачные системы на AWS или YandexCloud с хранением баз данных у провайдеров баз данных или в этих же системах.
Резервное копирование данных предусмотреть в отдельные системы долговременного хранения (например отдельная услуга у компании Selectel по хранение бекапов).
Сам код и его компоненты следует вести в системах контроля версий (GitLab, GitHub, BitBucket, и иные с поддержкой CI/CD для бесшовной развертки на продакшн окружение)
Все функциональные сервисы должны в рамках собственного репозитория содержать Dockerfile описывающий формирование докер-контейнера.
Все вычислительные сервисы могут располагаться в облачном сегменте приложения и масштабироваться в зависимости от нагрузки или решая вопросы георезервирования. Доступ к API клиентам предоставляется по доменному имени или IP с помощью балансировщика нагрузки (Внутреннего или в ручном виде) перенаправлением на нужные сегменты обработки запросов (API). Сегмент приложения ниже API не доступен клиентам ни в каком виде.
### 1. Система организации очередей
В качестве организации системы очередей традиционно предлагается использовать сервис RabbitMQ. Данный функционал обязательно должен быть выведен из Kebernetes и располагаться на изолированной виртуальной машине.
### 2. Система обработки поступивших сообщений
Для определения стратегии решения задачи в области обработки поступивших сообщений не хватает требований в части скорости принятия решения или обработки сообщения. Будем исходить из требований к системе приближенной к системе реального времени, в которой скорость реакции на появление в системе сообщения от устройства должна регламентироваться секундами. Тогда для достижения подобного результата предлагается к разработке микросевисы-демоны написанные на языках C (Си) или GoLang, способные в многопоточном режиме обеспечить разбор сообщений из менеджера очередей и сохранение их в системе долговременного хранения оригинальных сообщений.
Именно на этом уровне предлагается отсеивать дубликаты (а именно помечать сообщения как дубликаты, все равно сохраняя).
### 3. Система долговременного хранения не реляционных данных
После обработкой демоном сообщения системе помещаются в систему пермоментного хранения данных. Ключевой принцип: любое поступившее сообщение хранится в системе. Для определение механизма хранения необходимо более детальное изучение особенностей приложения. Если данные представляют собой сложно не реляционные данные то в качестве системы управления предлагается MongoDb или ClickHouse. И та и другая система имеет свои достоинства и недостатки. для определения механизма нужно понимать перспективы развития продукта и его потенциальное масштабировнаие. Если планируется гео-резервирование или любой механизм шардинга данных то в качестве системы хранения и упралвения лучше подойдет MongoDB. Если имеет место скорость доступа - то правильным решением будет использовать ClickHouse.
Но! если есть возможность преобразовать данные к реляционными то постоянное хранение лучше выполнить в реляционном виде и наилучшим решением будет хранение данных в СУБД PostreSQL, так как она позволяет и шардиться во все стороны и индексировать вплоть до конкретных полей в JSON полях. В этом случае самым удачным решением будет совмещение этого типа хранилища с хранилищем реляционных данных описанное в следующем пункте.
### 4. Система долговременного хранения реляционных данных
В качестве хранения всех операционных данных необходимых для расчетов для анализа активности, а так же все о текущем состоянии устройств предлагается хранить в хранилище реляционных данных PosgreSQL. Все же рассчитанные значения, аналитика по дням предлагается хранить в отдельном сегменте системы долговременного хранения. Данное решение позволит изменять структуру хранения отчета об активности и быстрый доступ по конкретным периодам если правильно расставить индексы.
### 5. Система обработки сообщений из долговременного хранилища и отдача сообщений клиенту (API)
Данная система может быть разработана в рамках подсистемы обработки поступивших сообщений на одном из представленных языках, в случае если требуется реакция системы в режиме реального времени. Иначе же предлагается на PHP, используя один из популярных фреймворков (YII2, Laravel), разработать проактивную систему обработки всех сообщений, аггрегацию сообщений в отчеты за период, а также систему авторизации и предоставления данных клиентам приложения.
### 6. Описание принципов решения задачи
Остановимся на механизмах решения поставленных задач подробнее:
``
отсеивать дублирующиеся пакеты (по типу пакета и timestamp)
``
Предлагается не отсеивать сообщения, а хранить все сообщения вне зависимости от того является оно дубликатом или нет. Это нужно для того, чтобы защитить себя от возможных сбоев сети и использовать их повторно при пересчете устройств. Если сообщения поступившие в систему являются полным дубликатом и не содержат в себе никакой различной информации (например - устройства передающие сообщения могут посылать информацию о качестве сети или иную системную информацию), то тогда данная задача решается исключительно на уровне Подсистемы обработки поступивших сообщений. Для быстрого функционирования системы предлагается ввести в использование хэш-функцию для определения строкового вида сообщения и при сохранении сообщения указывать результат расчета хэша в качестве индекса в коллекции/таблице. При поступлении сообщения можно проверять это сообщение по хэшу и в случае дубликата игнорировать его. Для оптимизации работы этого алгоритма предлагается рассмотреть возможность использования систем хранения в оперативной памяти хэшей поступивших сообщения (Memcache, Redis).
``
отдавать последнюю координату устройства
``
После сохранения поступившего сообщения, по CRON запускается механизм разбора сообщения. Все последние знания об устройстве предлагается хранить в виде строки описания самого устройства в подсистеме хранения реляционных данных. При запросе последних координат по устройству достаточно будет сделать запрос на получение ORM модели в реляцию по устройству откуда можно будет взять последние координаты и на это потребуется всего один запрос по индексу.
``
отдавать текущие координаты устройств внутри определенного bounding box
``
Эта задача не совсем понятна, если планируется поиск устройства по координатам с целью отображения на карте в замкнутом диапазоне, то также как и описано в предыдущем пункте одним запросом в подсистему хранения реляции с индексом. Если нужны пуши (например для поиска питомца) о перемещении то задача другая и скорее всего уведомления стоит включать на подсистеме обработке сообщений и отправлять пуш на любое сообщение устройства с координатами. Но тут следует предусмотреть возможность включения режима поиска и сброс этого режима через какое то время.... Ну в общем скорее всего это другая задача...  
``
сохранять и агрегировать статистику по активности, отдельно вычислять активность которая была в рамках записи трека
``
А вот сохранять агрегированную информацию по активности предлагается в не реляционном виде. В процессе обработки ранее сохраненных сообщений сообщения помечаются как ``processed:true``  и в случае запуска по cron расчета при наличии сообщений со статусом отличным от ``processed:true`` начинается расчет по алгоритму и в хронологии имеющихся сообщений.
``
отправлять пуш уведомления при изменения статус устройства
``
Пуш уведомления отправлять в процессе разбора сообщения в подсистеме обработке сообщений, при изменении статуса отправляется пуш уведомление, после сохранения статуса в базе данных.
``
описать алгоритм работы подсистемы, вычисляющей совместные прогулки
``
При обработке сообщений у новых сообщений необходимо предусмотреть для новых сообщений статус ```checked_walk: false```. Отдельным методом запускаемым по cron для устройств у которых есть сообщения со статусом ```checked_walk: false``` происходит поиск совместных прогулок по алгоритму: ищем в радиусе (по прямому условию на концевые координаты прямоугольника с учетом погрешности) устройства которые были в интервале времени 10 минут от сообщения. В случае сопоставлении пары устройств создается запись в отдельной таблице связывающих устройство поиска с найденным устройством с указанием по устройству поиска первого и последнего timestamp для которого найденное устройство обнаружено. 
### 7. Программный код части поставленной задачи
 
Данная задача для реализации объемна и я не располагаю достаточным количеством времени на полную реализацию, но я могу выполнить любое лаконичное задание которое позволило бы вам понять уровень моей компетенции на любой технологии описанной в настоящем решении.
